{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tugas 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Dalam Tugas 1 ini, Anda akan melakukan analisis regresi menggunakan dataset cuaca dari Szeged, Hungaria, yang mencakup periode dari tahun 2006 hingga 2016. Dataset ini berisi informasi harian dan per jam mengenai suhu, tekanan, kecepatan angin, dan parameter cuaca lainnya.</p>\n",
    "\n",
    "<p>Tujuan Tugas:</p>\n",
    "<ul>\n",
    "    <li> Menerapkan teknik-teknik analisis regresi untuk memodelkan hubungan antara variabel independen (seperti suhu, tekanan, dan kecepatan angin) dengan variabel dependen yang ditentukan.</li>\n",
    "    <li> Mengevaluasi kinerja model regresi menggunakan metrik yang sesuai.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Selama praktikum ini, Anda akan diminta untuk mengisi beberapa bagian kode program yang kosong. Pastikan Anda mengisi bagian-bagian tersebut dengan cermat, karena kode yang belum lengkap perlu diisi agar program dapat berjalan dengan baik dan model regresi dapat diterapkan dengan benar. Instruksi dan penjelasan lebih lanjut akan diberikan di bagian-bagian terkait dalam notebook ini.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebelum memulai analisis, kita akan mengimpor beberapa library penting dan mengatur opsi tampilan untuk memastikan seluruh data dapat dilihat dengan jelas di notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path):\n",
    "    \"\"\"\n",
    "    Memuat file CSV ke dalam DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"Error: File '{file_path}' not found!\")\n",
    "\n",
    "        # Gantilah bagian ini dengan kode untuk membaca file CSV menggunakan pandas.\n",
    "        df = ...\n",
    "\n",
    "        print(f\"CSV file! Shape: {df.shape}\")\n",
    "\n",
    "        return df\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(fnf_error)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"Error: The CSV file is empty!\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"Error: CSV parsing issue. Check the file format.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    return None \n",
    "\n",
    "\"\"\"\n",
    "Ganti ... dengan path file CSV\n",
    "\"\"\"\n",
    "df = load_csv(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk memeriksa apakah ada nilai yang hilang dalam dataset, kita akan menghitung jumlah nilai **null** pada setiap kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena terdapat nilai null dalam dataset, kita akan menghapus baris yang mengandung nilai null untuk memastikan data yang digunakan bersih dan lengkap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null_rows(df):\n",
    "    \"\"\"\n",
    "    Menghapus baris yang mengandung nilai null.\n",
    "    \"\"\"\n",
    "    initial_shape = df.shape\n",
    "    print(f\"Shape awal: {initial_shape}\")\n",
    "    \n",
    "    # Gantilah bagian ini dengan kode untuk menghapus baris yang mengandung nilai null.\n",
    "    ...\n",
    "    \n",
    "    final_shape = df.shape\n",
    "    print(f\"Baris dengan nilai null telah dihapus. Shape baru: {final_shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = remove_null_rows(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini, kita akan memeriksa apakah terdapat baris duplikat dalam dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ditemukan bahwa dataset ini mengandung baris duplikat. Baris duplikat ini perlu dihapus untuk memastikan kualitas dan akurasi analisis yang lebih baik. Pada langkah selanjutnya, kita akan menghapus baris-baris duplikat ini agar data yang digunakan bersih dan tidak mengandung duplikasi yang dapat mempengaruhi hasil model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_rows(df):\n",
    "    \"\"\"\n",
    "    Menghapus baris yang duplikat.\n",
    "    \"\"\"\n",
    "    initial_shape = df.shape\n",
    "    print(f\"Shape awal: {initial_shape}\")\n",
    "    \n",
    "    # Gantilah bagian ini dengan kode untuk menghapus baris yang duplikat.\n",
    "    ...\n",
    "    \n",
    "    final_shape = df.shape\n",
    "    print(f\"Baris duplikat telah dihapus. Shape baru: {final_shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = remove_duplicate_rows(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kasus dataset ini, kita akan menghapus dua kolom, yaitu **'Formatted Date'** dan **'Daily Summary'**, karena keduanya tidak relevan untuk analisis lebih lanjut. Oleh karena itu, kolom-kolom tersebut akan dihapus dari dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Formatted Date', 'Daily Summary']\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada dataset ini terdapat suatu atribut bernama **Wind Bearing**. **Wind Bearing** dalam dataset ini menunjukkan arah angin yang diukur dalam derajat dengan referensi terhadap utara geografis. Nilai **wind bearing** menunjukkan arah dari mana angin berasal, dengan 0Â° atau 360Â° berarti angin datang dari utara, 90Â° dari timur, 180Â° dari selatan, dan 270Â° dari barat. Arah ini penting dalam analisis cuaca untuk memahami pola angin dan dampaknya terhadap kondisi cuaca lainnya.\n",
    "\n",
    "Untuk tugas ini, **wind bearing** yang merupakan data numerik akan dikonversi menjadi **kategori**. Hal ini dilakukan untuk memudahkan analisis dan pelatihan model, karena kategori arah angin (seperti **Utara**, **Timur**, **Selatan**, dan **Barat**) lebih mudah dipahami dan diinterpretasikan dalam konteks analisis model, terutama dalam model klasifikasi atau pengelompokan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_wind_bearing(wind_bearing):\n",
    "    \"\"\"\n",
    "    Mengonversi nilai wind bearing (arah angin) menjadi kategori berdasarkan rentang derajat.\n",
    "    \"\"\"\n",
    "    if 0 <= wind_bearing < 45 or wind_bearing == 360:\n",
    "        return 'Utara Timur Laut (NE)'\n",
    "    elif 45 <= wind_bearing < 90:\n",
    "        return 'Timur Laut (E)'\n",
    "    elif 90 <= wind_bearing < 135:\n",
    "        return 'Selatan Timur Laut (SE)'\n",
    "    elif 135 <= wind_bearing < 180:\n",
    "        return 'Selatan (S)'\n",
    "    elif 180 <= wind_bearing < 225:\n",
    "        return 'Selatan Barat Laut (SW)'\n",
    "    elif 225 <= wind_bearing < 270:\n",
    "        return 'Barat Laut (W)'\n",
    "    elif 270 <= wind_bearing < 315:\n",
    "        return 'Utara Barat Laut (NW)'\n",
    "    elif 315 <= wind_bearing < 360:\n",
    "        return 'Utara (N)'\n",
    "\n",
    "def add_wind_bearing_category(df, col_name):\n",
    "    \"\"\"\n",
    "    Menambahkan kolom kategori arah angin berdasarkan kolom wind_bearing.\n",
    "    \"\"\"\n",
    "    df[col_name] = df[col_name].apply(categorize_wind_bearing)\n",
    "    return df\n",
    "\n",
    "df = add_wind_bearing_category(df, 'Wind Bearing (degrees)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kode berikut, kita akan mengklasifikasikan kolom-kolom dalam dataset menjadi tiga kategori utama: **binary**, **numerical**, dan **categorical**. Kolom dengan tipe data numerik yang memiliki dua nilai unik akan dimasukkan dalam kategori **binary**, sedangkan kolom numerik lainnya akan masuk dalam kategori **numerical**. Kolom dengan tipe data **object** atau **category** yang memiliki dua nilai unik akan dikategorikan sebagai **binary**, dan kolom lainnya akan dimasukkan ke dalam kategori **categorical**. Kode ini akan membantu mempermudah analisis data dan pelatihan model berdasarkan jenis fitur yang ada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_columns(df):\n",
    "    \"\"\"\n",
    "    Mengklasifikasikan kolom kedalam jenis binary, numerical, dan categorical.\n",
    "    \"\"\"\n",
    "    binary_cols = []\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']: \n",
    "            if df[col].nunique() == 2:\n",
    "                binary_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        elif df[col].dtype == 'object' or df[col].dtype.name == 'category':  \n",
    "            if df[col].nunique() == 2: \n",
    "                binary_cols.append(col)\n",
    "            else:\n",
    "                categorical_cols.append(col)\n",
    "        elif df[col].dtype == 'bool':  \n",
    "            binary_cols.append(col) \n",
    "\n",
    "    return binary_cols, numerical_cols, categorical_cols\n",
    "\n",
    "binary_cols, numerical_cols, categorical_cols = classify_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang, kita akan memasuki tahap visualisasi distribusi pada atribut numerik. Proses ini bertujuan untuk melihat bagaimana distribusi nilai pada masing-masing atribut numerik dalam dataset, yang akan membantu kita memahami karakteristik data, mendeteksi pola, serta identifikasi potensi masalah seperti skewness atau outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(df, numerical_cols):\n",
    "    \"\"\"\n",
    "    Plot histograms for numerical features to visualize their distributions.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_plots = len(numerical_cols)\n",
    "    num_rows = (num_plots // 3) + (1 if num_plots % 3 != 0 else 0)  \n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, num_rows * 3))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        sns.histplot(df[col], kde=False, bins=30, color='skyblue', edgecolor='black', ax=axes[i])\n",
    "        axes[i].set_title(f\"Histogram of {col}\")\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel(\"Frequency\")\n",
    "    \n",
    "    for i in range(num_plots, len(axes)):\n",
    "        axes[i].axis('off') \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada plot yang dihasilkan, dapat dilihat bahwa atribut **Wind Speed** dan **Humidity** memiliki distribusi yang **skewed**.\n",
    "\n",
    "**Skewed** berarti distribusi data tidak simetris. Ada dua jenis skewness:\n",
    "- **Positive Skew (Right Skew):** Data terkonsentrasi di sisi kiri dan ekor lebih panjang di sisi kanan.\n",
    "- **Negative Skew (Left Skew):** Data terkonsentrasi di sisi kanan dan ekor lebih panjang di sisi kiri.\n",
    "\n",
    "Distribusi yang **skewed** menunjukkan bahwa data tidak terdistribusi secara normal.\n",
    "\n",
    "**Distribusi normal** adalah distribusi simetris di mana data terpusat di tengah (mean), dan semakin menjauh dari pusat, semakin sedikit data yang ada. Biasanya, distribusi normal membentuk kurva lonceng. Model analisis seperti regresi mengasumsikan distribusi data normal, sehingga data yang skewed perlu diubah.\n",
    "\n",
    "Untuk itu, kita akan melakukan **transformasi** pada atribut **Wind Speed** dan **Humidity** untuk mengatasi skewness dan membuat distribusinya lebih mendekati distribusi normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan menggunakan transformasi untuk mengatasi **skewness** pada atribut yang distribusinya tidak normal, agar distribusi data menjadi lebih mendekati distribusi normal.\n",
    "\n",
    "Pada atribut **Wind Speed (km/h)**, kita akan menggunakan **log transform**. Ini bertujuan untuk mengurangi skewness positif (right skew) dan membuat distribusi data lebih simetris, sehingga model dapat lebih baik dalam mempelajari hubungan antar fitur dan target.\n",
    "\n",
    "Sedangkan pada atribut **Humidity**, kita akan menggunakan **square root transform**. Transformasi ini membantu mengurangi skewness dan memperbaiki distribusi data, sehingga analisis dan pelatihan model menjadi lebih stabil dan efektif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(df, col):\n",
    "    \"\"\"\n",
    "    Apply log transformation to a numerical feature.\n",
    "    \"\"\"\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "def sqrt_transform(df, col):\n",
    "    \"\"\"\n",
    "    Applies square root transformation to handle left-skewed data.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[col] = df[col] ** 0.5\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = log_transform(df, 'Wind Speed (km/h)')\n",
    "df = sqrt_transform(df, 'Humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapatkah anda melihat perbedaan distribusi pada atribut **Wind Speed (km/h)** dan **Humidity** sebelum dan sesudah dilakukan transformasi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita akan membuat plot **boxplot** untuk memvisualisasikan distribusi data pada setiap atribut numerik. Dengan menggunakan boxplot, kita dapat melihat beberapa informasi penting, salah satunya mendeteksi adanya **outlier** yang mungkin mempengaruhi analisis dan pelatihan model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(df, numerical_cols):\n",
    "    \"\"\"\n",
    "    Plot boxplots for numerical features to visualize the distribution and detect outliers.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_plots = len(numerical_cols)\n",
    "    num_rows = (num_plots // 3) + (1 if num_plots % 3 != 0 else 0)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, 3, figsize=(10, num_rows * 3))\n",
    "    axes = axes.flatten() \n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        sns.boxplot(x=df[col], color='lightgreen', ax=axes[i])\n",
    "        axes[i].set_title(f\"Boxplot of {col}\")\n",
    "        axes[i].set_xlabel(col)\n",
    "    \n",
    "    for i in range(num_plots, len(axes)):\n",
    "        axes[i].axis('off') \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk bisa mengetahui lebih jelas mengenai jumlah outlier yang terdapat pada masing-masing atribut, kita akan menghitung persentase **outlier** untuk setiap atribut numerik menggunakan metode **Interquartile Range (IQR)**. Dengan cara ini, kita dapat mengetahui sejauh mana data pada masing-masing atribut memiliki nilai ekstrim yang dapat mempengaruhi analisis dan pelatihan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers(df, column):\n",
    "    \"\"\"\n",
    "    Menghitung persentase outlier pada suatu fitur menggunakan metode IQR.\n",
    "    \"\"\"\n",
    "    # Menghitung Q1 (kuartil pertama), Q3 (kuartil ketiga), dan IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Menentukan batas bawah dan batas atas untuk outlier\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Menentukan jumlah outlier\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    \n",
    "    # Menghitung persentase outlier\n",
    "    percentage_outliers = (len(outliers) / len(df)) * 100\n",
    "    \n",
    "    return percentage_outliers\n",
    "\n",
    "for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    percentage_outliers = calculate_outliers(df, col)\n",
    "    print(f\"{col}: {percentage_outliers:.2f}% outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena persentase outlier yang ada cukup kecil, kita memutuskan untuk **tidak menghapus outlier** dalam dataset ini dan akan melanjutkan proses analisis dan pelatihan model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita akan melakukan **scaling** pada beberapa atribut numerik agar fitur-fitur tersebut berada dalam rentang yang sesuai untuk digunakan dalam model. Beberapa atribut akan kita **standardize** untuk mendapatkan distribusi dengan rata-rata 0 dan variansi 1, sementara yang lainnya akan kita **min-max scale** agar nilainya berada dalam rentang 0 hingga 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale(df, col):\n",
    "    \"\"\"\n",
    "    Menykalakan nilai fitur antara 0 dan 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Isi dengan rumus untuk melakukan Min-Max scaling pada kolom tertentu\n",
    "    df[col] = ...\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standard_scale(df, col):\n",
    "    \"\"\"\n",
    "    Menstandarisasi nilai fitur agar memiliki rata-rata 0 dan variansi 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Isi dengan rumus untuk melakukan Standard scaling pada kolom tertentu\n",
    "    df[col] = ...\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = standard_scale(df, 'Temperature (C)')\n",
    "df = standard_scale(df, 'Apparent Temperature (C)')\n",
    "df = minmax_scale(df, 'Humidity')\n",
    "df = standard_scale(df, 'Wind Speed (km/h)')\n",
    "df = minmax_scale(df, 'Visibility (km)')\n",
    "df = minmax_scale(df, 'Pressure (millibars)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita akan melakukan **Label Encoding** pada fitur kategorikal yang ada dalam dataset. **Label Encoding** akan mengubah nilai kategori menjadi angka, yang memungkinkan kita untuk memprosesnya dalam model pembelajaran mesin. Pada contoh ini, kita akan melakukan encoding pada kolom-kolom seperti **Summary**, **Precip Type**, dan **Wind Bearing (degrees)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def label_encode(df, col):\n",
    "    \"\"\"\n",
    "    Encode categorical features using label encoding.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Isi dengan kode untuk melakukan label encoder pada kolom tertentu\n",
    "    ...\n",
    "    df[col] = ...\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = label_encode(df, 'Summary')\n",
    "df = label_encode(df, 'Precip Type')\n",
    "df = label_encode(df, 'Wind Bearing (degrees)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, kita akan melihat **heatmap korelasi** untuk memvisualisasikan hubungan antara fitur-fitur dalam dataset. Heatmap ini akan membantu kita memahami seberapa kuat hubungan antar variabel dan apakah terdapat fitur yang sangat berkorelasi, yang dapat mempengaruhi model yang akan dibangun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df, numerical_cols):\n",
    "    \"\"\"\n",
    "    Plot a heatmap to visualize the correlation between numerical features.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    correlation_matrix = df[numerical_cols].corr() \n",
    "    \n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"ğŸ”¹ Correlation Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(df, df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam dataset ini, **Apparent Temperature (C)** merupakan variabel target atau **y** yang ingin kita prediksi. Dari hasil heatmap korelasi, kita dapat melihat bahwa beberapa atribut memiliki keterkaitan dengan **Apparent Temperature**, meskipun korelasi tersebut tidak terlalu kuat. Banyak atribut yang menunjukkan **ketidak-korelasi** yang signifikan dengan **Apparent Temperature**.\n",
    "\n",
    "Namun demikian, meskipun korelasi antar fitur tidak terlalu tinggi dengan target, kita akan tetap menggunakan **seluruh atribut** yang tersedia untuk melatih model. Hal ini bertujuan untuk memberikan model data yang lebih kaya dan memungkinkan eksplorasi yang lebih baik terhadap hubungan antara fitur dan target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya adalah mempersiapkan data untuk melatih model. Pertama-tama, kita akan membagi dataset menjadi dua bagian, yaitu **training set** dan **test set** menggunakan teknik **train-test split**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_split_custom(df, target_col, test_size=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Function to split data into training and testing sets.\n",
    "    \"\"\"\n",
    "    X = ...\n",
    "    y = ...\n",
    "\n",
    "    # Gantilah bagian ini dengan kode untuk membagi data menjadi training dan testing set.\n",
    "    X_train, X_test, y_train, y_test = ...\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_custom(df, \"Apparent Temperature (C)\", test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mempersiapkan data, langkah berikutnya adalah melatih model regresi. Pada tugas ini, kita akan melatih beberapa model regresi untuk memprediksi **Apparent Temperature** berdasarkan fitur-fitur yang ada dalam dataset. Model regresi yang akan digunakan termasuk **Linear Regression**, **Ridge Regression**, **Decision Tree Regressor**, **Random Forest Regressor**, **Gradient Boosting**, dan **Support Vector Regressor**. Tujuan dari pelatihan ini adalah untuk mengevaluasi kinerja masing-masing model menggunakan metrik yang sesuai dan memilih model terbaik berdasarkan hasil yang diperoleh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "def train_models_regression(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and compare multiple regression models\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Ridge Regression\": Ridge(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(),\n",
    "        \"Random Forest\": RandomForestRegressor(),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "        \"SVR\": SVR()\n",
    "    }\n",
    "    \n",
    "    print(\"ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹\")\n",
    "    for name, model in models.items():\n",
    "        ## Isi dengan kode untuk melatih model\n",
    "        ...\n",
    "        y_pred = ...\n",
    "        \n",
    "        # Calculate RÂ² and Mean Squared Error\n",
    "        r2 = ...\n",
    "        mse = ...\n",
    "        \n",
    "        print(\"ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹\")\n",
    "        print(f\"{name}\\nRÂ²: {r2:.4f}\\nMean Squared Error: {mse:.4f}\")\n",
    "        print(\"ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹\")\n",
    "    \n",
    "    print(\"ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹ğŸ”¹\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models_regression(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah melatih beberapa model regresi dan memperoleh metrik evaluasi untuk masing-masing model, langkah selanjutnya adalah memberikan **interpretasi** mengenai hasil yang diperoleh. Praktikan diminta untuk menganalisis perbandingan antara model-model yang telah dilatih berdasarkan **RÂ² (R-squared)** dan **Mean Squared Error (MSE)**.\n",
    "\n",
    "- **Model yang lebih baik** dapat dilihat dari nilai **RÂ²** yang lebih tinggi dan **MSE** yang lebih rendah.\n",
    "- Bandingkan kinerja model-model yang digunakan dan tentukan model mana yang paling efektif dalam memprediksi **Apparent Temperature**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jawaban praktikan:\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
